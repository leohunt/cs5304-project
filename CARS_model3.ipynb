{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in\n",
    "# Note that there are no NANs in these data; '?' is\n",
    "# used when there is missing information\n",
    "accepts = pd.read_csv('./RCdata/chefmozaccepts.csv')\n",
    "cuisine = pd.read_csv('./RCdata/chefmozcuisine.csv')\n",
    "hours = pd.read_csv('./RCdata/chefmozhours4.csv')\n",
    "parking = pd.read_csv('./RCdata/chefmozparking.csv')\n",
    "geo = pd.read_csv('./RCdata/geoplaces2.csv',  encoding='latin-1') \n",
    "usercuisine = pd.read_csv('./RCdata/usercuisine.csv')\n",
    "payment = pd.read_csv('./RCdata/userpayment.csv')\n",
    "profile = pd.read_csv('./RCdata/userprofile.csv')\n",
    "rating = pd.read_csv('./RCdata/rating_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data together\n",
    "# Restaurant\n",
    "res_all = np.concatenate((accepts.placeID.unique(), cuisine.placeID.unique(), \n",
    "                          hours.placeID.unique(), parking.placeID.unique(), geo.placeID.unique()))\n",
    "res_all = np.sort( np.unique(res_all) ) # All the placeID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User\n",
    "user_all = np.concatenate((usercuisine.userID.unique(), payment.userID.unique(), \n",
    "                           profile.userID.unique()))\n",
    "user_all = np.sort( np.unique(user_all) ) # All the userID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating\n",
    "overall_rating = pd.DataFrame( np.zeros((len(res_all),len(user_all)))-1.0, \n",
    "                              columns=user_all, index=res_all )\n",
    "food_rating = overall_rating.copy()\n",
    "service_rating = overall_rating.copy() \n",
    "\n",
    "for r, u, o, f, s in zip(rating.placeID, rating.userID, rating.rating, rating.food_rating, \n",
    "                         rating.service_rating):\n",
    "    overall_rating.loc[r,u] = o\n",
    "    food_rating.loc[r,u] = f\n",
    "    service_rating.loc[r,u] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review\n",
    "review = pd.DataFrame( np.zeros(overall_rating.shape), columns=user_all, index=res_all)\n",
    "review[overall_rating >= 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cusine\n",
    "# use dummy variables for different cuisine categories of the restaurants\n",
    "res_cuisine = pd.get_dummies(cuisine,columns=['Rcuisine'])\n",
    "\n",
    "# remove duplicate restaurant ID's. \n",
    "# A restaurant with multiple cuisine categories would have multiple columns equal 1\n",
    "res_cuisine = res_cuisine.groupby('placeID',as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking\n",
    "res_parking = parking.copy()\n",
    "res_parking.parking_lot = res_parking.parking_lot.map({'fee':1, 'none':0, 'public':1, 'yes':2,\n",
    "                                        'street':1, 'valet parking':1, 'validated parking':1})\n",
    "\n",
    "# remove duplicate restaurant ID's. \n",
    "# A restaurant with multiple parking options may have a value > 2\n",
    "res_parking = res_parking.groupby('placeID',as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information\n",
    "res_info = geo[['latitude','longitude','placeID','name','address','city','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Service\n",
    "# These features should be relevant for rating prediction since they are about services \n",
    "# and price. Especially, 'alcohol','smoking_area', and 'price' relate to 'drink_level', \n",
    "# 'smoker', and 'budget' in the user profiles \n",
    "res_service_price = geo[['placeID','alcohol','smoking_area','other_services','price']]\n",
    "# 1 if alcohol is available, 0 otherwise\n",
    "res_service_price.alcohol = res_service_price.alcohol.map(lambda x: 0 if x == 'No_Alcohol_Served' else 1)\n",
    "# 1 if there is smoking area, 0 otherwise\n",
    "res_service_price.smoking_area = res_service_price.smoking_area.map(lambda x: 0 if (x == 'none') | (x == 'not permitted') else 1)\n",
    "# 1 if other services are available, 0 otherwise\n",
    "res_service_price.other_services = res_service_price.other_services.map(lambda x: 0 if x == 'none'  else 1)\n",
    "# map price levels to numbers\n",
    "res_service_price.price = res_service_price.price.map({'low': 1, 'medium': 2, 'high': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "# Whether these features are relevant is not so clear\n",
    "res_environment = geo[['placeID','dress_code','accessibility','Rambience','area']]\n",
    "# 1 if formal dress is required, 0 otherwise\n",
    "res_environment.dress_code = res_environment.dress_code.map({'informal':0, 'casual':0, 'formal': 1})\n",
    "# map accessibility levels to numbers\n",
    "res_environment.accessibility = res_environment.accessibility.map({'no_accessibility':0, 'partially':1, 'completely': 2})\n",
    "res_environment.Rambience = res_environment.Rambience.map({'familiar':0, 'quiet': 1})\n",
    "res_environment.area = res_environment.area.map({'open':0, 'closed':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(938, 69)\n"
     ]
    }
   ],
   "source": [
    "# Combine all information into one data frame\n",
    "df_res = pd.DataFrame({'placeID': res_all})\n",
    "df_res = pd.merge(left=df_res, right=res_cuisine, how=\"left\", on=\"placeID\")\n",
    "df_res = pd.merge(left=df_res, right=res_parking, how=\"left\", on=\"placeID\")\n",
    "df_res = pd.merge(left=df_res, right=res_service_price, how=\"left\", on=\"placeID\")\n",
    "df_res = pd.merge(left=df_res, right=res_environment, how=\"left\", on=\"placeID\")\n",
    "\n",
    "print(df_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The placeID's for the 130 restaurants with ratings\n",
    "res_rated = res_all[np.sum(review,axis=1) > 0] \n",
    "\n",
    "# tells us whether a restaurant-user pair has a rating. 0 means No and 1 means Yes.\n",
    "R = review.loc[res_rated].values  # shape = (130,138)\n",
    "\n",
    "Y_service = service_rating.loc[res_rated].values\n",
    "Y_overall = overall_rating.loc[res_rated].values\n",
    "Y_food  = food_rating.loc[res_rated].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the indices of \"df_res\" where a restaurant has ratings\n",
    "index = np.array([x in res_rated for x in df_res['placeID'].values])\n",
    "index = np.where(index == True)[0]\n",
    "# restaurant features for the 130 restaurants with ratings\n",
    "X = df_res.loc[index, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the NA\n",
    "X = X.fillna(0) # fill all NANs with 0\n",
    "# drop a feature if the entire column are 0\n",
    "features_to_drop = X.columns.values[np.sum(X,axis=0) == 0] \n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "X = X.drop(['placeID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select several features for consideration\n",
    "X = X[['parking_lot','alcohol','smoking_area','other_services','price','dress_code','accessibility']]\n",
    "X['x0'] = 1 # add a bias term for linear regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876.0\n",
      "285.0\n"
     ]
    }
   ],
   "source": [
    "# Split Training and Validation set\n",
    "num_rating = np.round(np.sum(R,axis=0)) # number of ratings from each user (minimum = 3)\n",
    "\n",
    "# 25% of the existing ratings will be used as the validation set\n",
    "# So during the training, they will be flagged \n",
    "g = lambda x: int(round(x*0.25)) \n",
    "flag = np.array( [g(x) for x in num_rating] )\n",
    "\n",
    "random.seed(0)\n",
    "cond = True\n",
    "\n",
    "while cond:\n",
    "\n",
    "    R_train = R.copy()\n",
    "\n",
    "    # loop over each user\n",
    "    for i in range(R_train.shape[1]):\n",
    "        # the restaurants that are rated\n",
    "        index = list( np.where(R_train[:,i] == 1)[0] )  \n",
    "        # randomly select about 25% of them to be flagged\n",
    "        index_flag = random.sample(index,flag[i])\n",
    "        R_train[index_flag,i] = 0  \n",
    "    \n",
    "    # make sure in the traning set, each restaurant and each user receives/gives at least \n",
    "    # 2 ratings\n",
    "    if (np.sum(R_train,axis=0).min() > 1) & (np.sum(R_train,axis=1).min() > 1): \n",
    "        cond = False\n",
    "        \n",
    "R_valid = R - R_train \n",
    "# Now \"R_train\" contains 876 ones, and \"R_valid\" contains 285 ones (\"R\" contains 1161 ones)\n",
    "# The shape of \"R\", \"R_train\" and \"R_valid\" are all (130,138)  \n",
    "print(R_train.sum())\n",
    "print(R_valid.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "# 1. RMSE\n",
    "# 2. FCP\n",
    "# FCP\n",
    "def FCP(Y,Y_pred,R):\n",
    "    \n",
    "    # list of true ratings from each user (we only select users with at least two ratings)\n",
    "    Y_fcp = []  \n",
    "    Y_pred_fcp = [] # list of predicted ratings from each user \n",
    "    n_user = R.shape[1]\n",
    "    \n",
    "    for i in range(n_user):\n",
    "        \n",
    "        cond = (R.sum(axis=0) >= 2)[i] # there should be at least two ratings from a user\n",
    "        index = np.where( R[:,i] == 1)[0] # the indices (restaurants) with ratings\n",
    "    \n",
    "        if cond:\n",
    "            \n",
    "            Y_fcp.append( (Y*R)[:,i][index] )\n",
    "            Y_pred_fcp.append( (Y_pred*R)[:,i][index] )\n",
    "\n",
    "        \n",
    "    n_fcp = len(Y_fcp) # number of users with at least two ratings\n",
    "    TP = 0. # Total number of pairs\n",
    "    DP = 0. # number of discordant pairs\n",
    "    CP = 0. # number of concordant pairs (excluding ties)\n",
    "    \n",
    "    for i in range(n_fcp):\n",
    "        \n",
    "        num_Y = len(Y_fcp[i])   # number of ratings from a user\n",
    "        TP += num_Y*(num_Y-1)/2 # number of rating pairs = n*(n+1)/2 \n",
    "\n",
    "        greater = np.array([])\n",
    "        greater_pred = np.array([])\n",
    "\n",
    "        # this loop is to go over all the rating pairs\n",
    "        for j in range(num_Y-1):\n",
    "            \n",
    "            not_equal = Y_fcp[i][j] != Y_fcp[i][j+1:]\n",
    "            greater = Y_fcp[i][j] > Y_fcp[i][j+1:]\n",
    "            greater_pred = Y_pred_fcp[i][j] > Y_pred_fcp[i][j+1:]\n",
    "\n",
    "            # filter the ones that are not ties\n",
    "            greater = greater[not_equal]\n",
    "            greater_pred = greater_pred[not_equal]\n",
    "\n",
    "            DP += (greater != greater_pred).sum()\n",
    "            CP += (greater == greater_pred).sum()\n",
    "            \n",
    "    print(\"Total number of rating pairs: {}\".format(int(TP)))\n",
    "    print(\"Total number of discordant pairs: {}\".format(int(DP)))\n",
    "    print(\"Total number of concordant pairs: {}\".format(int(CP)))\n",
    "    print(\"Total number of ties: {}\".format(int(TP-DP-CP)))\n",
    "    print(\"FCP: {}\".format(CP/(CP+DP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMean(Y,R):\n",
    "\n",
    "    Y = Y*R\n",
    "    mean =  (np.sum(Y, axis=1)/np.sum((R == 1.0), axis=1)).reshape(Y.shape[0],1) * np.ones(Y.shape)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.6930171831949701\n",
      "RMSE of the validation set: 0.828933960093509\n"
     ]
    }
   ],
   "source": [
    "Y = Y_overall \n",
    "Y_mean = GetMean(Y,R_train) # get the average ratings based on the training set\n",
    "Y_pred = np.zeros(Y.shape) + Y_mean # prediction \n",
    "\n",
    "# RMSE\n",
    "print(\"RMSE of the training set: {}\".format(np.sqrt(mean_squared_error(Y[R_train == 1], Y_pred[R_train == 1]))))\n",
    "print(\"RMSE of the validation set: {}\".format(np.sqrt(mean_squared_error(Y[R_valid == 1], Y_pred[R_valid == 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2808\n",
      "Total number of discordant pairs: 395\n",
      "Total number of concordant pairs: 859\n",
      "Total number of ties: 1554\n",
      "FCP: 0.6850079744816587\n",
      "\n",
      "\n",
      "Validation Set:\n",
      "Total number of rating pairs: 201\n",
      "Total number of discordant pairs: 32\n",
      "Total number of concordant pairs: 39\n",
      "Total number of ties: 130\n",
      "FCP: 0.5492957746478874\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set:\")\n",
    "FCP(Y,Y_pred,R_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-Based Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters of the cost function are the weights of all the users, with a shape = \n",
    "# (n_user, n_feature), where n_user = 138 = number of users, and n_feature = 8 = number \n",
    "# of restaurant features (including the bias term). However, to feed the cost function \n",
    "# to SciPy's minimize(), the parameters of the function cannot be a matrix and has to be \n",
    "# a 1D vector\n",
    "\n",
    "def CostFunction(params, X, Y, R, lambd): # lambd is the L2 regularization coefficient\n",
    "    \n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    # reshape the parameters to a 2D matrix so we can perform matrix factorization\n",
    "    Theta = params.reshape(num_user, num_feature)\n",
    "    J = 0.5 * np.sum( (np.dot(X, Theta.T) * R - Y)**2 )\n",
    "\n",
    "    # regularization\n",
    "    J = J + lambd/2. * np.sum(Theta[:,:-1]**2) \n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def Gradient(params, X, Y, R, lambd):\n",
    "    \n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    Theta = params.reshape(num_user, num_feature)\n",
    "    Theta_grad = np.dot((np.dot(Theta, X.T) * R.T - Y.T), X)\n",
    "\n",
    "    # regularization\n",
    "    Theta_grad[:,:-1] = Theta_grad[:,:-1] + lambd*Theta[:,:-1]\n",
    "\n",
    "    return Theta_grad.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanNorm(Y,R):\n",
    "    \n",
    "    Y_norm = Y*R\n",
    "    mean =  (np.sum(Y_norm, axis=1)/np.sum((R == 1.0), axis=1)).reshape(Y.shape[0],1) * np.ones(Y.shape)\n",
    "    Y_norm = (Y_norm - mean)*R\n",
    "\n",
    "    return Y_norm, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 109.024339\n",
      "         Iterations: 206\n",
      "         Function evaluations: 277\n",
      "         Gradient evaluations: 277\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "Y_norm, Y_mean = MeanNorm(Y,R_train)\n",
    "\n",
    "n_user = R.shape[1]\n",
    "n_feature = X.shape[1]\n",
    "lambd = 64. # L2 regularization; I ran the optimization multiple times with different values \n",
    "            # (1, 2, 4, 8...) and 64 results in the best validation FCP\n",
    "    \n",
    "Theta = np.random.normal(0,1,(n_user, n_feature)).reshape(-1) # initialize the weights\n",
    "\n",
    "result = minimize(CostFunction, Theta, jac=Gradient, args=(X, Y_norm, R_train, lambd),\n",
    "                  options={'disp': True, 'maxiter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.49150999391290773\n",
      "RMSE of the validation set: 0.6992958907746744\n"
     ]
    }
   ],
   "source": [
    "# Result\n",
    "# RMSE\n",
    "Theta_opt = result.x.reshape(n_user, n_feature) # reshape the optimial parameters to a 2D matrix \n",
    "Y_pred = np.dot(X, Theta_opt.T) + Y_mean\n",
    "print(\"RMSE of the training set: {}\".format(np.sqrt(mean_squared_error(Y[R_train == 1], Y_pred[R_train == 1]))))\n",
    "print(\"RMSE of the validation set: {}\".format(np.sqrt(mean_squared_error(Y[R_valid == 1], Y_pred[R_valid == 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2808\n",
      "Total number of discordant pairs: 356\n",
      "Total number of concordant pairs: 898\n",
      "Total number of ties: 1554\n",
      "FCP: 0.7161084529505582\n",
      "\n",
      "\n",
      "Validation Set:\n",
      "Total number of rating pairs: 201\n",
      "Total number of discordant pairs: 31\n",
      "Total number of concordant pairs: 40\n",
      "Total number of ties: 130\n",
      "FCP: 0.5633802816901409\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set:\")\n",
    "FCP(Y,Y_pred,R_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-Based Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoker</th>\n",
       "      <th>drink_level</th>\n",
       "      <th>transport</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   smoker  drink_level  transport  budget\n",
       "0       0            1          0       2\n",
       "1       0            1          0       1\n",
       "2       0            3          0       1\n",
       "3       0            1          0       2\n",
       "4       0            1          0       2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User certain attributes\n",
    "user_info = profile[['smoker','drink_level','transport','budget']]\n",
    "\n",
    "# 1 for smokers, 0 otherwise; assume '?' to be non-smokers\n",
    "user_info.smoker = user_info.smoker.map({'false': 0, 'true': 1, '?': 0})\n",
    "# map drink levels to numbers\n",
    "user_info.drink_level = user_info.drink_level.map({'abstemious': 1, 'casual drinker': 2, 'social drinker': 3})\n",
    "# 1 for car owners, 0 otherwise; assume '?' to be not car owners\n",
    "user_info.transport = user_info.transport.map({'public':0, 'car owner':1, 'on foot':0, '?':0})\n",
    "# map budget levels to numbers; assume '?' to be medium\n",
    "user_info.budget = user_info.budget.map({'medium':2, 'low':1, 'high':3, '?':2})\n",
    "\n",
    "user_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta_modifier = pd.DataFrame(np.ones((n_user, n_feature)), columns=X.columns.values) \n",
    "Theta_modifier['parking_lot'] = user_info['transport'] # 0 or 1\n",
    "Theta_modifier['alcohol'] = user_info['drink_level'] # 1, 2 or 3\n",
    "Theta_modifier['smoking_area'] = user_info['smoker'] # 0 or 1\n",
    "Theta_modifier['price'] = 1.0/user_info['budget'] # 1 (low), 1/2 (medium) or 1/3 (high)\n",
    "Theta_modifier = Theta_modifier.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CostFunction2(params, X, Y, R, Theta_modifier, lambd):\n",
    "\n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    # reshape the Theta_modifier to 1-D\n",
    "    Theta_temp = Theta_modifier.reshape(-1)\n",
    "    # elements with non-zero values in Theta_modifier are multiplied to the input weights\n",
    "    Theta_temp[Theta_temp > 0] = Theta_temp[Theta_temp > 0] * params\n",
    "    \n",
    "    # reshape the parameters to a 2D matrix so we can perform matrix factorization.\n",
    "    # Elements with zero values in Theta_modifier always remain 0 in this matrix (for those \n",
    "    # users who don't have a car and those who don't smoke)\n",
    "    Theta = Theta_temp.reshape(num_user, num_feature)\n",
    "    J = 0.5 * np.sum( (np.dot(X, Theta.T) * R - Y)**2 )\n",
    "\n",
    "    # regularization\n",
    "    J = J + lambd/2. * np.sum(Theta[:,:-1]**2) \n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def Gradient2(params, X, Y, R, Theta_modifier, lambd):\n",
    "\n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    Theta_temp = Theta_modifier.reshape(-1)\n",
    "    Theta_temp[Theta_temp > 0] = Theta_temp[Theta_temp > 0] * params\n",
    "\n",
    "    Theta = Theta_temp.reshape(num_user, num_feature)\n",
    "    Theta_grad = np.dot((np.dot(Theta, X.T) * R.T - Y.T), X) \n",
    "\n",
    "    # regularization\n",
    "    Theta_grad[:,:-1] = Theta_grad[:,:-1] + lambd*Theta[:,:-1]\n",
    "    Theta_grad = Theta_grad * Theta_modifier\n",
    "\n",
    "    Theta_grad = Theta_grad[Theta_modifier > 0]\n",
    "    \n",
    "    return Theta_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 110.032844\n",
      "         Iterations: 235\n",
      "         Function evaluations: 282\n",
      "         Gradient evaluations: 282\n"
     ]
    }
   ],
   "source": [
    "lambd = 64. # L2 regularization; I ran the optimization multiple times with different values \n",
    "            # (1, 2, 4, 8...) and 64 results in the best validation FCP\n",
    "    \n",
    "Theta = np.random.normal(0,1,(n_user, n_feature))[Theta_modifier > 0] # initialize the weights\n",
    "\n",
    "result = minimize(CostFunction2, Theta, jac=Gradient2, args=(X, Y_norm, R_train, Theta_modifier, \n",
    "                  lambd), options={'disp': True, 'maxiter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.49590893838210204\n",
      "RMSE of the validation set: 0.6986709053292303\n"
     ]
    }
   ],
   "source": [
    "# elements with non-zero values in Theta_modifier are multiplied to the optimal weights\n",
    "Theta_transformer = Theta_modifier.reshape(-1)\n",
    "Theta_transformer[Theta_transformer > 0] = Theta_transformer[Theta_transformer > 0] * result.x\n",
    "# reshape the parameters to a 2D matrix \n",
    "Theta_opt = Theta_transformer.reshape(n_user, n_feature)\n",
    "\n",
    "Y_pred = np.dot(X, Theta_opt.T) + Y_mean\n",
    "\n",
    "# RMSE\n",
    "print(\"RMSE of the training set: {}\".format(np.sqrt(mean_squared_error(Y[R_train == 1], Y_pred[R_train == 1]))))\n",
    "print(\"RMSE of the validation set: {}\".format(np.sqrt(mean_squared_error(Y[R_valid == 1], Y_pred[R_valid == 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2808\n",
      "Total number of discordant pairs: 362\n",
      "Total number of concordant pairs: 892\n",
      "Total number of ties: 1554\n",
      "FCP: 0.7113237639553429\n",
      "\n",
      "\n",
      "Validation Set:\n",
      "Total number of rating pairs: 201\n",
      "Total number of discordant pairs: 31\n",
      "Total number of concordant pairs: 40\n",
      "Total number of ties: 130\n",
      "FCP: 0.5633802816901409\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set:\")\n",
    "FCP(Y,Y_pred,R_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U1001</th>\n",
       "      <th>U1002</th>\n",
       "      <th>U1003</th>\n",
       "      <th>U1004</th>\n",
       "      <th>U1005</th>\n",
       "      <th>U1006</th>\n",
       "      <th>U1007</th>\n",
       "      <th>U1008</th>\n",
       "      <th>U1009</th>\n",
       "      <th>U1010</th>\n",
       "      <th>...</th>\n",
       "      <th>U1129</th>\n",
       "      <th>U1130</th>\n",
       "      <th>U1131</th>\n",
       "      <th>U1132</th>\n",
       "      <th>U1133</th>\n",
       "      <th>U1134</th>\n",
       "      <th>U1135</th>\n",
       "      <th>U1136</th>\n",
       "      <th>U1137</th>\n",
       "      <th>U1138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132560</th>\n",
       "      <td>0.163739</td>\n",
       "      <td>0.604283</td>\n",
       "      <td>0.456769</td>\n",
       "      <td>0.681650</td>\n",
       "      <td>0.354380</td>\n",
       "      <td>0.582535</td>\n",
       "      <td>0.042386</td>\n",
       "      <td>0.409461</td>\n",
       "      <td>0.709452</td>\n",
       "      <td>0.316296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241337</td>\n",
       "      <td>0.275990</td>\n",
       "      <td>0.497432</td>\n",
       "      <td>0.652353</td>\n",
       "      <td>0.372582</td>\n",
       "      <td>0.296975</td>\n",
       "      <td>-0.880664</td>\n",
       "      <td>0.547155</td>\n",
       "      <td>0.787210</td>\n",
       "      <td>0.834625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132561</th>\n",
       "      <td>0.545510</td>\n",
       "      <td>0.988817</td>\n",
       "      <td>0.811936</td>\n",
       "      <td>0.987383</td>\n",
       "      <td>0.686475</td>\n",
       "      <td>0.928679</td>\n",
       "      <td>0.406147</td>\n",
       "      <td>0.754006</td>\n",
       "      <td>1.017195</td>\n",
       "      <td>0.669804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837818</td>\n",
       "      <td>1.005382</td>\n",
       "      <td>0.644856</td>\n",
       "      <td>0.563836</td>\n",
       "      <td>-0.535511</td>\n",
       "      <td>0.911746</td>\n",
       "      <td>1.171390</td>\n",
       "      <td>1.167959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132564</th>\n",
       "      <td>1.128844</td>\n",
       "      <td>1.572150</td>\n",
       "      <td>1.395270</td>\n",
       "      <td>1.570717</td>\n",
       "      <td>1.269808</td>\n",
       "      <td>1.512012</td>\n",
       "      <td>0.989481</td>\n",
       "      <td>1.337339</td>\n",
       "      <td>1.600528</td>\n",
       "      <td>1.253138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.172855</td>\n",
       "      <td>1.148102</td>\n",
       "      <td>1.421151</td>\n",
       "      <td>1.588715</td>\n",
       "      <td>1.228189</td>\n",
       "      <td>1.147169</td>\n",
       "      <td>0.047822</td>\n",
       "      <td>1.495079</td>\n",
       "      <td>1.754724</td>\n",
       "      <td>1.751292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132572</th>\n",
       "      <td>0.801921</td>\n",
       "      <td>1.245227</td>\n",
       "      <td>1.068346</td>\n",
       "      <td>1.243794</td>\n",
       "      <td>0.942885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.010416</td>\n",
       "      <td>1.273605</td>\n",
       "      <td>0.885864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845932</td>\n",
       "      <td>0.821179</td>\n",
       "      <td>1.134477</td>\n",
       "      <td>1.261792</td>\n",
       "      <td>0.943213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.279101</td>\n",
       "      <td>1.176240</td>\n",
       "      <td>1.427801</td>\n",
       "      <td>1.424369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132583</th>\n",
       "      <td>1.187958</td>\n",
       "      <td>1.629883</td>\n",
       "      <td>1.467686</td>\n",
       "      <td>1.667850</td>\n",
       "      <td>1.353761</td>\n",
       "      <td>1.588747</td>\n",
       "      <td>1.057600</td>\n",
       "      <td>1.415067</td>\n",
       "      <td>1.696657</td>\n",
       "      <td>1.336471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.248762</td>\n",
       "      <td>1.253713</td>\n",
       "      <td>1.490896</td>\n",
       "      <td>1.662201</td>\n",
       "      <td>1.331566</td>\n",
       "      <td>1.263739</td>\n",
       "      <td>0.125246</td>\n",
       "      <td>1.566482</td>\n",
       "      <td>1.812634</td>\n",
       "      <td>1.834625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           U1001     U1002     U1003     U1004     U1005     U1006     U1007  \\\n",
       "132560  0.163739  0.604283  0.456769  0.681650  0.354380  0.582535  0.042386   \n",
       "132561  0.545510  0.988817  0.811936  0.987383  0.686475  0.928679  0.406147   \n",
       "132564  1.128844  1.572150  1.395270  1.570717  1.269808  1.512012  0.989481   \n",
       "132572  0.801921  1.245227  1.068346  1.243794  0.942885  0.000000  0.000000   \n",
       "132583  1.187958  1.629883  1.467686  1.667850  1.353761  1.588747  1.057600   \n",
       "\n",
       "           U1008     U1009     U1010    ...        U1129     U1130     U1131  \\\n",
       "132560  0.409461  0.709452  0.316296    ...     0.241337  0.275990  0.497432   \n",
       "132561  0.754006  1.017195  0.669804    ...     0.000000  0.000000  0.837818   \n",
       "132564  1.337339  1.600528  1.253138    ...     1.172855  1.148102  1.421151   \n",
       "132572  1.010416  1.273605  0.885864    ...     0.845932  0.821179  1.134477   \n",
       "132583  1.415067  1.696657  1.336471    ...     1.248762  1.253713  1.490896   \n",
       "\n",
       "           U1132     U1133     U1134     U1135     U1136     U1137     U1138  \n",
       "132560  0.652353  0.372582  0.296975 -0.880664  0.547155  0.787210  0.834625  \n",
       "132561  1.005382  0.644856  0.563836 -0.535511  0.911746  1.171390  1.167959  \n",
       "132564  1.588715  1.228189  1.147169  0.047822  1.495079  1.754724  1.751292  \n",
       "132572  1.261792  0.943213  0.000000 -0.279101  1.176240  1.427801  1.424369  \n",
       "132583  1.662201  1.331566  1.263739  0.125246  1.566482  1.812634  1.834625  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_test =  R*(-1) + 1.0 # 1 for those without existing ratings, 0 otherwise\n",
    "\n",
    "# predicted ratings for the restaurants that each user hasn't visited\n",
    "Y_final = Y_pred * R_test\n",
    "Y_final = pd.DataFrame( Y_final, columns=user_all, index=res_rated )\n",
    "Y_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
