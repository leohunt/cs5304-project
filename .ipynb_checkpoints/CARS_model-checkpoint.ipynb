{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in\n",
    "# Note that there are no NANs in these data; '?' is\n",
    "# used when there is missing information\n",
    "accepts = pd.read_csv('./RCdata/chefmozaccepts.csv')\n",
    "cuisine = pd.read_csv('./RCdata/chefmozcuisine.csv')\n",
    "hours = pd.read_csv('./RCdata/chefmozhours4.csv')\n",
    "parking = pd.read_csv('./RCdata/chefmozparking.csv')\n",
    "geo = pd.read_csv('./RCdata/geoplaces2.csv',  encoding='latin-1') \n",
    "usercuisine = pd.read_csv('./RCdata/usercuisine.csv')\n",
    "payment = pd.read_csv('./RCdata/userpayment.csv')\n",
    "profile = pd.read_csv('./RCdata/userprofile.csv')\n",
    "rating = pd.read_csv('./RCdata/rating_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data together\n",
    "# Restaurant\n",
    "res_all = np.concatenate((accepts.placeID.unique(), cuisine.placeID.unique(), \n",
    "                          hours.placeID.unique(), parking.placeID.unique(), geo.placeID.unique()))\n",
    "res_all = np.sort( np.unique(res_all) ) # All the placeID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User\n",
    "user_all = np.concatenate((usercuisine.userID.unique(), payment.userID.unique(), \n",
    "                           profile.userID.unique()))\n",
    "user_all = np.sort( np.unique(user_all) ) # All the userID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating\n",
    "overall_rating = pd.DataFrame( np.zeros((len(res_all),len(user_all)))-1.0, \n",
    "                              columns=user_all, index=res_all )\n",
    "food_rating = overall_rating.copy()\n",
    "service_rating = overall_rating.copy() \n",
    "\n",
    "for r, u, o, f, s in zip(rating.placeID, rating.userID, rating.rating, rating.food_rating, \n",
    "                         rating.service_rating):\n",
    "    overall_rating.loc[r,u] = o\n",
    "    food_rating.loc[r,u] = f\n",
    "    service_rating.loc[r,u] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review\n",
    "review = pd.DataFrame( np.zeros(overall_rating.shape), columns=user_all, index=res_all)\n",
    "review[overall_rating >= 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cusine\n",
    "# use dummy variables for different cuisine categories of the restaurants\n",
    "res_cuisine = pd.get_dummies(cuisine,columns=['Rcuisine'])\n",
    "\n",
    "# remove duplicate restaurant ID's. \n",
    "# A restaurant with multiple cuisine categories would have multiple columns equal 1\n",
    "res_cuisine = res_cuisine.groupby('placeID',as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking\n",
    "res_parking = parking.copy()\n",
    "res_parking.parking_lot = res_parking.parking_lot.map({'fee':1, 'none':0, 'public':1, 'yes':2,\n",
    "                                        'street':1, 'valet parking':1, 'validated parking':1})\n",
    "\n",
    "# remove duplicate restaurant ID's. \n",
    "# A restaurant with multiple parking options may have a value > 2\n",
    "res_parking = res_parking.groupby('placeID',as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information\n",
    "res_info = geo[['latitude','longitude','placeID','name','address','city','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Service\n",
    "# These features should be relevant for rating prediction since they are about services \n",
    "# and price. Especially, 'alcohol','smoking_area', and 'price' relate to 'drink_level', \n",
    "# 'smoker', and 'budget' in the user profiles \n",
    "res_service_price = geo[['placeID','alcohol','smoking_area','other_services','price']]\n",
    "# 1 if alcohol is available, 0 otherwise\n",
    "res_service_price.alcohol = res_service_price.alcohol.map(lambda x: 0 if x == 'No_Alcohol_Served' else 1)\n",
    "# 1 if there is smoking area, 0 otherwise\n",
    "res_service_price.smoking_area = res_service_price.smoking_area.map(lambda x: 0 if (x == 'none') | (x == 'not permitted') else 1)\n",
    "# 1 if other services are available, 0 otherwise\n",
    "res_service_price.other_services = res_service_price.other_services.map(lambda x: 0 if x == 'none'  else 1)\n",
    "# map price levels to numbers\n",
    "res_service_price.price = res_service_price.price.map({'low': 1, 'medium': 2, 'high': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "# Whether these features are relevant is not so clear\n",
    "res_environment = geo[['placeID','dress_code','accessibility','Rambience','area']]\n",
    "# 1 if formal dress is required, 0 otherwise\n",
    "res_environment.dress_code = res_environment.dress_code.map({'informal':0, 'casual':0, 'formal': 1})\n",
    "# map accessibility levels to numbers\n",
    "res_environment.accessibility = res_environment.accessibility.map({'no_accessibility':0, 'partially':1, 'completely': 2})\n",
    "res_environment.Rambience = res_environment.Rambience.map({'familiar':0, 'quiet': 1})\n",
    "res_environment.area = res_environment.area.map({'open':0, 'closed':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(938, 69)\n"
     ]
    }
   ],
   "source": [
    "# Combine all information into one data frame\n",
    "df_res = pd.DataFrame({'placeID': res_all})\n",
    "df_res = pd.merge(left=df_res, right=res_cuisine, how=\"left\", on=\"placeID\")\n",
    "df_res = pd.merge(left=df_res, right=res_parking, how=\"left\", on=\"placeID\")\n",
    "df_res = pd.merge(left=df_res, right=res_service_price, how=\"left\", on=\"placeID\")\n",
    "df_res = pd.merge(left=df_res, right=res_environment, how=\"left\", on=\"placeID\")\n",
    "\n",
    "print(df_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The placeID's for the 130 restaurants with ratings\n",
    "res_rated = res_all[np.sum(review,axis=1) > 0] \n",
    "\n",
    "# tells us whether a restaurant-user pair has a rating. 0 means No and 1 means Yes.\n",
    "R = review.loc[res_rated].values  # shape = (130,138)\n",
    "\n",
    "Y_service = service_rating.loc[res_rated].values\n",
    "Y_overall = overall_rating.loc[res_rated].values\n",
    "Y_food  = food_rating.loc[res_rated].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the indices of \"df_res\" where a restaurant has ratings\n",
    "index = np.array([x in res_rated for x in df_res['placeID'].values])\n",
    "index = np.where(index == True)[0]\n",
    "# restaurant features for the 130 restaurants with ratings\n",
    "X = df_res.loc[index, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the NA\n",
    "X = X.fillna(0) # fill all NANs with 0\n",
    "# drop a feature if the entire column are 0\n",
    "features_to_drop = X.columns.values[np.sum(X,axis=0) == 0] \n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "X = X.drop(['placeID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select several features for consideration\n",
    "X = X[['parking_lot','alcohol','smoking_area','other_services','price','dress_code','accessibility']]\n",
    "X['x0'] = 1 # add a bias term for linear regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876.0\n",
      "285.0\n"
     ]
    }
   ],
   "source": [
    "# Split Training and Validation set\n",
    "num_rating = np.round(np.sum(R,axis=0)) # number of ratings from each user (minimum = 3)\n",
    "\n",
    "# 25% of the existing ratings will be used as the validation set\n",
    "# So during the training, they will be flagged \n",
    "g = lambda x: int(round(x*0.25)) \n",
    "flag = np.array( [g(x) for x in num_rating] )\n",
    "\n",
    "random.seed(0)\n",
    "cond = True\n",
    "\n",
    "while cond:\n",
    "\n",
    "    R_train = R.copy()\n",
    "\n",
    "    # loop over each user\n",
    "    for i in range(R_train.shape[1]):\n",
    "        # the restaurants that are rated\n",
    "        index = list( np.where(R_train[:,i] == 1)[0] )  \n",
    "        # randomly select about 25% of them to be flagged\n",
    "        index_flag = random.sample(index,flag[i])\n",
    "        R_train[index_flag,i] = 0  \n",
    "    \n",
    "    # make sure in the traning set, each restaurant and each user receives/gives at least \n",
    "    # 2 ratings\n",
    "    if (np.sum(R_train,axis=0).min() > 1) & (np.sum(R_train,axis=1).min() > 1): \n",
    "        cond = False\n",
    "        \n",
    "R_valid = R - R_train \n",
    "# Now \"R_train\" contains 876 ones, and \"R_valid\" contains 285 ones (\"R\" contains 1161 ones)\n",
    "# The shape of \"R\", \"R_train\" and \"R_valid\" are all (130,138)  \n",
    "print(R_train.sum())\n",
    "print(R_valid.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "# 1. RMSE\n",
    "# 2. FCP\n",
    "# FCP\n",
    "def FCP(Y,Y_pred,R):\n",
    "    \n",
    "    # list of true ratings from each user (we only select users with at least two ratings)\n",
    "    Y_fcp = []  \n",
    "    Y_pred_fcp = [] # list of predicted ratings from each user \n",
    "    n_user = R.shape[1]\n",
    "    \n",
    "    for i in range(n_user):\n",
    "        \n",
    "        cond = (R.sum(axis=0) >= 2)[i] # there should be at least two ratings from a user\n",
    "        index = np.where( R[:,i] == 1)[0] # the indices (restaurants) with ratings\n",
    "    \n",
    "        if cond:\n",
    "            \n",
    "            Y_fcp.append( (Y*R)[:,i][index] )\n",
    "            Y_pred_fcp.append( (Y_pred*R)[:,i][index] )\n",
    "\n",
    "        \n",
    "    n_fcp = len(Y_fcp) # number of users with at least two ratings\n",
    "    TP = 0. # Total number of pairs\n",
    "    DP = 0. # number of discordant pairs\n",
    "    CP = 0. # number of concordant pairs (excluding ties)\n",
    "    \n",
    "    for i in range(n_fcp):\n",
    "        \n",
    "        num_Y = len(Y_fcp[i])   # number of ratings from a user\n",
    "        TP += num_Y*(num_Y-1)/2 # number of rating pairs = n*(n+1)/2 \n",
    "\n",
    "        greater = np.array([])\n",
    "        greater_pred = np.array([])\n",
    "\n",
    "        # this loop is to go over all the rating pairs\n",
    "        for j in range(num_Y-1):\n",
    "            \n",
    "            not_equal = Y_fcp[i][j] != Y_fcp[i][j+1:]\n",
    "            greater = Y_fcp[i][j] > Y_fcp[i][j+1:]\n",
    "            greater_pred = Y_pred_fcp[i][j] > Y_pred_fcp[i][j+1:]\n",
    "\n",
    "            # filter the ones that are not ties\n",
    "            greater = greater[not_equal]\n",
    "            greater_pred = greater_pred[not_equal]\n",
    "\n",
    "            DP += (greater != greater_pred).sum()\n",
    "            CP += (greater == greater_pred).sum()\n",
    "            \n",
    "    print(\"Total number of rating pairs: {}\".format(int(TP)))\n",
    "    print(\"Total number of discordant pairs: {}\".format(int(DP)))\n",
    "    print(\"Total number of concordant pairs: {}\".format(int(CP)))\n",
    "    print(\"Total number of ties: {}\".format(int(TP-DP-CP)))\n",
    "    print(\"FCP: {}\".format(CP/(CP+DP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMean(Y,R):\n",
    "\n",
    "    Y = Y*R\n",
    "    mean =  (np.sum(Y, axis=1)/np.sum((R == 1.0), axis=1)).reshape(Y.shape[0],1) * np.ones(Y.shape)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.6930171831949701\n",
      "RMSE of the validation set: 0.828933960093509\n"
     ]
    }
   ],
   "source": [
    "Y = Y_overall \n",
    "Y_mean = GetMean(Y,R_train) # get the average ratings based on the training set\n",
    "Y_pred = np.zeros(Y.shape) + Y_mean # prediction \n",
    "\n",
    "# RMSE\n",
    "print(\"RMSE of the training set: {}\".format(np.sqrt(mean_squared_error(Y[R_train == 1], Y_pred[R_train == 1]))))\n",
    "print(\"RMSE of the validation set: {}\".format(np.sqrt(mean_squared_error(Y[R_valid == 1], Y_pred[R_valid == 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2808\n",
      "Total number of discordant pairs: 395\n",
      "Total number of concordant pairs: 859\n",
      "Total number of ties: 1554\n",
      "FCP: 0.6850079744816587\n",
      "\n",
      "\n",
      "Validation Set:\n",
      "Total number of rating pairs: 201\n",
      "Total number of discordant pairs: 32\n",
      "Total number of concordant pairs: 39\n",
      "Total number of ties: 130\n",
      "FCP: 0.5492957746478874\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set:\")\n",
    "FCP(Y,Y_pred,R_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-Based Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters of the cost function are the weights of all the users, with a shape = \n",
    "# (n_user, n_feature), where n_user = 138 = number of users, and n_feature = 8 = number \n",
    "# of restaurant features (including the bias term). However, to feed the cost function \n",
    "# to SciPy's minimize(), the parameters of the function cannot be a matrix and has to be \n",
    "# a 1D vector\n",
    "\n",
    "def CostFunction(params, X, Y, R, lambd): # lambd is the L2 regularization coefficient\n",
    "    \n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    # reshape the parameters to a 2D matrix so we can perform matrix factorization\n",
    "    Theta = params.reshape(num_user, num_feature)\n",
    "    J = 0.5 * np.sum( (np.dot(X, Theta.T) * R - Y)**2 )\n",
    "\n",
    "    # regularization\n",
    "    J = J + lambd/2. * np.sum(Theta[:,:-1]**2) \n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def Gradient(params, X, Y, R, lambd):\n",
    "    \n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    Theta = params.reshape(num_user, num_feature)\n",
    "    Theta_grad = np.dot((np.dot(Theta, X.T) * R.T - Y.T), X)\n",
    "\n",
    "    # regularization\n",
    "    Theta_grad[:,:-1] = Theta_grad[:,:-1] + lambd*Theta[:,:-1]\n",
    "\n",
    "    return Theta_grad.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanNorm(Y,R):\n",
    "    \n",
    "    Y_norm = Y*R\n",
    "    mean =  (np.sum(Y_norm, axis=1)/np.sum((R == 1.0), axis=1)).reshape(Y.shape[0],1) * np.ones(Y.shape)\n",
    "    Y_norm = (Y_norm - mean)*R\n",
    "\n",
    "    return Y_norm, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 109.024339\n",
      "         Iterations: 206\n",
      "         Function evaluations: 277\n",
      "         Gradient evaluations: 277\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "Y_norm, Y_mean = MeanNorm(Y,R_train)\n",
    "\n",
    "n_user = R.shape[1]\n",
    "n_feature = X.shape[1]\n",
    "lambd = 64. # L2 regularization; I ran the optimization multiple times with different values \n",
    "            # (1, 2, 4, 8...) and 64 results in the best validation FCP\n",
    "    \n",
    "Theta = np.random.normal(0,1,(n_user, n_feature)).reshape(-1) # initialize the weights\n",
    "\n",
    "result = minimize(CostFunction, Theta, jac=Gradient, args=(X, Y_norm, R_train, lambd),\n",
    "                  options={'disp': True, 'maxiter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.49150999391290773\n",
      "RMSE of the validation set: 0.6992958907746744\n"
     ]
    }
   ],
   "source": [
    "# Result\n",
    "# RMSE\n",
    "Theta_opt = result.x.reshape(n_user, n_feature) # reshape the optimial parameters to a 2D matrix \n",
    "Y_pred = np.dot(X, Theta_opt.T) + Y_mean\n",
    "print(\"RMSE of the training set: {}\".format(np.sqrt(mean_squared_error(Y[R_train == 1], Y_pred[R_train == 1]))))\n",
    "print(\"RMSE of the validation set: {}\".format(np.sqrt(mean_squared_error(Y[R_valid == 1], Y_pred[R_valid == 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2808\n",
      "Total number of discordant pairs: 356\n",
      "Total number of concordant pairs: 898\n",
      "Total number of ties: 1554\n",
      "FCP: 0.7161084529505582\n",
      "\n",
      "\n",
      "Validation Set:\n",
      "Total number of rating pairs: 201\n",
      "Total number of discordant pairs: 31\n",
      "Total number of concordant pairs: 40\n",
      "Total number of ties: 130\n",
      "FCP: 0.5633802816901409\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set:\")\n",
    "FCP(Y,Y_pred,R_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-Based Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoker</th>\n",
       "      <th>drink_level</th>\n",
       "      <th>transport</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   smoker  drink_level  transport  budget\n",
       "0       0            1          0       2\n",
       "1       0            1          0       1\n",
       "2       0            3          0       1\n",
       "3       0            1          0       2\n",
       "4       0            1          0       2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User certain attributes\n",
    "user_info = profile[['smoker','drink_level','transport','budget']]\n",
    "\n",
    "# 1 for smokers, 0 otherwise; assume '?' to be non-smokers\n",
    "user_info.smoker = user_info.smoker.map({'false': 0, 'true': 1, '?': 0})\n",
    "# map drink levels to numbers\n",
    "user_info.drink_level = user_info.drink_level.map({'abstemious': 1, 'casual drinker': 2, 'social drinker': 3})\n",
    "# 1 for car owners, 0 otherwise; assume '?' to be not car owners\n",
    "user_info.transport = user_info.transport.map({'public':0, 'car owner':1, 'on foot':0, '?':0})\n",
    "# map budget levels to numbers; assume '?' to be medium\n",
    "user_info.budget = user_info.budget.map({'medium':2, 'low':1, 'high':3, '?':2})\n",
    "\n",
    "user_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta_modifier = pd.DataFrame(np.ones((n_user, n_feature)), columns=X.columns.values) \n",
    "Theta_modifier['parking_lot'] = user_info['transport'] # 0 or 1\n",
    "Theta_modifier['alcohol'] = user_info['drink_level'] # 1, 2 or 3\n",
    "Theta_modifier['smoking_area'] = user_info['smoker'] # 0 or 1\n",
    "Theta_modifier['price'] = 1.0/user_info['budget'] # 1 (low), 1/2 (medium) or 1/3 (high)\n",
    "Theta_modifier = Theta_modifier.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CostFunction2(params, X, Y, R, Theta_modifier, lambd):\n",
    "\n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    # reshape the Theta_modifier to 1-D\n",
    "    Theta_temp = Theta_modifier.reshape(-1)\n",
    "    # elements with non-zero values in Theta_modifier are multiplied to the input weights\n",
    "    Theta_temp[Theta_temp > 0] = Theta_temp[Theta_temp > 0] * params\n",
    "    \n",
    "    # reshape the parameters to a 2D matrix so we can perform matrix factorization.\n",
    "    # Elements with zero values in Theta_modifier always remain 0 in this matrix (for those \n",
    "    # users who don't have a car and those who don't smoke)\n",
    "    Theta = Theta_temp.reshape(num_user, num_feature)\n",
    "    J = 0.5 * np.sum( (np.dot(X, Theta.T) * R - Y)**2 )\n",
    "\n",
    "    # regularization\n",
    "    J = J + lambd/2. * np.sum(Theta[:,:-1]**2) \n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def Gradient2(params, X, Y, R, Theta_modifier, lambd):\n",
    "\n",
    "    num_user = R.shape[1]\n",
    "    num_feature = X.shape[1]\n",
    "\n",
    "    Theta_temp = Theta_modifier.reshape(-1)\n",
    "    Theta_temp[Theta_temp > 0] = Theta_temp[Theta_temp > 0] * params\n",
    "\n",
    "    Theta = Theta_temp.reshape(num_user, num_feature)\n",
    "    Theta_grad = np.dot((np.dot(Theta, X.T) * R.T - Y.T), X) \n",
    "\n",
    "    # regularization\n",
    "    Theta_grad[:,:-1] = Theta_grad[:,:-1] + lambd*Theta[:,:-1]\n",
    "    Theta_grad = Theta_grad * Theta_modifier\n",
    "\n",
    "    Theta_grad = Theta_grad[Theta_modifier > 0]\n",
    "    \n",
    "    return Theta_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 110.032844\n",
      "         Iterations: 235\n",
      "         Function evaluations: 282\n",
      "         Gradient evaluations: 282\n"
     ]
    }
   ],
   "source": [
    "lambd = 64. # L2 regularization; I ran the optimization multiple times with different values \n",
    "            # (1, 2, 4, 8...) and 64 results in the best validation FCP\n",
    "    \n",
    "Theta = np.random.normal(0,1,(n_user, n_feature))[Theta_modifier > 0] # initialize the weights\n",
    "\n",
    "result = minimize(CostFunction2, Theta, jac=Gradient2, args=(X, Y_norm, R_train, Theta_modifier, \n",
    "                  lambd), options={'disp': True, 'maxiter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.49590893838210204\n",
      "RMSE of the validation set: 0.6986709053292303\n"
     ]
    }
   ],
   "source": [
    "# elements with non-zero values in Theta_modifier are multiplied to the optimal weights\n",
    "Theta_transformer = Theta_modifier.reshape(-1)\n",
    "Theta_transformer[Theta_transformer > 0] = Theta_transformer[Theta_transformer > 0] * result.x\n",
    "# reshape the parameters to a 2D matrix \n",
    "Theta_opt = Theta_transformer.reshape(n_user, n_feature)\n",
    "\n",
    "Y_pred = np.dot(X, Theta_opt.T) + Y_mean\n",
    "\n",
    "# RMSE\n",
    "print(\"RMSE of the training set: {}\".format(np.sqrt(mean_squared_error(Y[R_train == 1], Y_pred[R_train == 1]))))\n",
    "print(\"RMSE of the validation set: {}\".format(np.sqrt(mean_squared_error(Y[R_valid == 1], Y_pred[R_valid == 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2808\n",
      "Total number of discordant pairs: 362\n",
      "Total number of concordant pairs: 892\n",
      "Total number of ties: 1554\n",
      "FCP: 0.7113237639553429\n",
      "\n",
      "\n",
      "Validation Set:\n",
      "Total number of rating pairs: 201\n",
      "Total number of discordant pairs: 31\n",
      "Total number of concordant pairs: 40\n",
      "Total number of ties: 130\n",
      "FCP: 0.5633802816901409\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Set:\")\n",
    "FCP(Y,Y_pred,R_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
